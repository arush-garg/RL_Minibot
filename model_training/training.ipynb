{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:  (array([ 0.03787199,  0.00376896, -0.00967403, -0.00565756], dtype=float32), {})\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial state: \", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the neural network model\n",
    "def create_model(input_shape, num_actions):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.InputLayer(shape=input_shape),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_actions, activation='linear')  # Outputs Q-values for each action\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,410</span> (68.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,410\u001b[0m (68.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,410</span> (68.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,410\u001b[0m (68.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = env.observation_space.shape\n",
    "num_actions = env.action_space.n\n",
    "model = create_model(input_shape, num_actions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time: 0.042786 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "sample_state = np.random.random((1, 4)).astype(np.float32)\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(1000):\n",
    "    _ = model.predict(sample_state, verbose=0)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Average inference time: {(end_time - start_time) / 1000:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "learning_rate = 0.0002\n",
    "gamma = 0.95  # Discount factor for future rewards\n",
    "epsilon = 1.0  # Initial exploration rate\n",
    "epsilon_min = 0.1  # Final exploration rate\n",
    "epsilon_decay = 0.999\n",
    "batch_size = 32\n",
    "memory_size = 5000\n",
    "num_episodes = 500\n",
    "max_steps_per_episode = 500\n",
    "\n",
    "replay_memory = deque(maxlen=memory_size)\n",
    "target_model = create_model(input_shape, num_actions)\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "#Target model is not compiled because it's weights are not getting updated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon-greedy policy for action selection\n",
    "def choose_action(state, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(num_actions)  # Explore\n",
    "    q_values = model.predict(state[np.newaxis], verbose=0)\n",
    "    return np.argmax(q_values[0])  # Exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Train the model using a batch of experiences\n",
    "def train_model():\n",
    "    if len(replay_memory) < batch_size:\n",
    "        return  # Wait until enough experiences are stored\n",
    "\n",
    "    batch = random.sample(replay_memory, batch_size)\n",
    "    states, actions, rewards, next_states, dones = map(np.array, zip(*batch))\n",
    "\n",
    "    # Compute target Q-values\n",
    "    next_q_values = target_model.predict(next_states, verbose=0)\n",
    "    max_next_q_values = np.max(next_q_values, axis=1)\n",
    "    target_q_values = rewards + gamma * max_next_q_values * (1 - dones)\n",
    "\n",
    "    # Update the model\n",
    "    q_values = model.predict(states, verbose=0)\n",
    "    for i, action in enumerate(actions):\n",
    "        q_values[i, action] = target_q_values[i]\n",
    "\n",
    "    model.fit(states, q_values, epochs=1, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 35.0\n",
      "Episode 2: Total Reward = 29.0\n",
      "Episode 3: Total Reward = 16.0\n",
      "Episode 4: Total Reward = 29.0\n",
      "Episode 5: Total Reward = 10.0\n",
      "Episode 6: Total Reward = 13.0\n",
      "Episode 7: Total Reward = 14.0\n",
      "Episode 8: Total Reward = 15.0\n",
      "Episode 9: Total Reward = 11.0\n",
      "Episode 10: Total Reward = 20.0\n",
      "Episode 11: Total Reward = 16.0\n",
      "Episode 12: Total Reward = 20.0\n",
      "Episode 13: Total Reward = 18.0\n",
      "Episode 14: Total Reward = 19.0\n",
      "Episode 15: Total Reward = 20.0\n",
      "Episode 16: Total Reward = 20.0\n",
      "Episode 17: Total Reward = 31.0\n",
      "Episode 18: Total Reward = 19.0\n",
      "Episode 19: Total Reward = 21.0\n",
      "Episode 20: Total Reward = 26.0\n",
      "Episode 21: Total Reward = 18.0\n",
      "Episode 22: Total Reward = 33.0\n",
      "Episode 23: Total Reward = 18.0\n",
      "Episode 24: Total Reward = 31.0\n",
      "Episode 25: Total Reward = 23.0\n",
      "Episode 26: Total Reward = 20.0\n",
      "Episode 27: Total Reward = 22.0\n",
      "Episode 28: Total Reward = 16.0\n",
      "Episode 29: Total Reward = 36.0\n",
      "Episode 30: Total Reward = 25.0\n",
      "Episode 31: Total Reward = 26.0\n",
      "Episode 32: Total Reward = 11.0\n",
      "Episode 33: Total Reward = 13.0\n",
      "Episode 34: Total Reward = 13.0\n",
      "Episode 35: Total Reward = 12.0\n",
      "Episode 36: Total Reward = 50.0\n",
      "Episode 37: Total Reward = 11.0\n",
      "Episode 38: Total Reward = 45.0\n",
      "Episode 39: Total Reward = 15.0\n",
      "Episode 40: Total Reward = 19.0\n",
      "Episode 41: Total Reward = 10.0\n",
      "Episode 42: Total Reward = 9.0\n",
      "Episode 43: Total Reward = 12.0\n",
      "Episode 44: Total Reward = 12.0\n",
      "Episode 45: Total Reward = 20.0\n",
      "Episode 46: Total Reward = 10.0\n",
      "Episode 47: Total Reward = 14.0\n",
      "Episode 48: Total Reward = 13.0\n",
      "Episode 49: Total Reward = 48.0\n",
      "Episode 50: Total Reward = 44.0\n",
      "Episode 51: Total Reward = 13.0\n",
      "Episode 52: Total Reward = 38.0\n",
      "Episode 53: Total Reward = 28.0\n",
      "Episode 54: Total Reward = 11.0\n",
      "Episode 55: Total Reward = 14.0\n",
      "Episode 56: Total Reward = 33.0\n",
      "Episode 57: Total Reward = 25.0\n",
      "Episode 58: Total Reward = 43.0\n",
      "Episode 59: Total Reward = 20.0\n",
      "Episode 60: Total Reward = 34.0\n",
      "Episode 61: Total Reward = 23.0\n",
      "Episode 62: Total Reward = 20.0\n",
      "Episode 63: Total Reward = 26.0\n",
      "Episode 64: Total Reward = 21.0\n",
      "Episode 65: Total Reward = 19.0\n",
      "Episode 66: Total Reward = 16.0\n",
      "Episode 67: Total Reward = 17.0\n",
      "Episode 68: Total Reward = 17.0\n",
      "Episode 69: Total Reward = 15.0\n",
      "Episode 70: Total Reward = 32.0\n",
      "Episode 71: Total Reward = 16.0\n",
      "Episode 72: Total Reward = 22.0\n",
      "Episode 73: Total Reward = 19.0\n",
      "Episode 74: Total Reward = 13.0\n",
      "Episode 75: Total Reward = 17.0\n",
      "Episode 76: Total Reward = 12.0\n",
      "Episode 77: Total Reward = 25.0\n",
      "Episode 78: Total Reward = 23.0\n",
      "Episode 79: Total Reward = 18.0\n",
      "Episode 80: Total Reward = 16.0\n",
      "Episode 81: Total Reward = 34.0\n",
      "Episode 82: Total Reward = 12.0\n",
      "Episode 83: Total Reward = 17.0\n",
      "Episode 84: Total Reward = 22.0\n",
      "Episode 85: Total Reward = 29.0\n",
      "Episode 86: Total Reward = 24.0\n",
      "Episode 87: Total Reward = 30.0\n",
      "Episode 88: Total Reward = 14.0\n",
      "Episode 89: Total Reward = 21.0\n",
      "Episode 90: Total Reward = 23.0\n",
      "Episode 91: Total Reward = 18.0\n",
      "Episode 92: Total Reward = 24.0\n",
      "Episode 93: Total Reward = 30.0\n",
      "Episode 94: Total Reward = 14.0\n",
      "Episode 95: Total Reward = 38.0\n",
      "Episode 96: Total Reward = 12.0\n",
      "Episode 97: Total Reward = 24.0\n",
      "Episode 98: Total Reward = 40.0\n",
      "Episode 99: Total Reward = 34.0\n",
      "Episode 100: Total Reward = 32.0\n",
      "Episode 101: Total Reward = 22.0\n",
      "Episode 102: Total Reward = 58.0\n",
      "Episode 103: Total Reward = 16.0\n",
      "Episode 104: Total Reward = 29.0\n",
      "Episode 105: Total Reward = 18.0\n",
      "Episode 106: Total Reward = 27.0\n",
      "Episode 107: Total Reward = 45.0\n",
      "Episode 108: Total Reward = 17.0\n",
      "Episode 109: Total Reward = 24.0\n",
      "Episode 110: Total Reward = 24.0\n",
      "Episode 111: Total Reward = 18.0\n",
      "Episode 112: Total Reward = 13.0\n",
      "Episode 113: Total Reward = 34.0\n",
      "Episode 114: Total Reward = 24.0\n",
      "Episode 115: Total Reward = 31.0\n",
      "Episode 116: Total Reward = 13.0\n",
      "Episode 117: Total Reward = 12.0\n",
      "Episode 118: Total Reward = 13.0\n",
      "Episode 119: Total Reward = 49.0\n",
      "Episode 120: Total Reward = 44.0\n",
      "Episode 121: Total Reward = 14.0\n",
      "Episode 122: Total Reward = 23.0\n",
      "Episode 123: Total Reward = 36.0\n",
      "Episode 124: Total Reward = 25.0\n",
      "Episode 125: Total Reward = 16.0\n",
      "Episode 126: Total Reward = 35.0\n",
      "Episode 127: Total Reward = 26.0\n",
      "Episode 128: Total Reward = 26.0\n",
      "Episode 129: Total Reward = 20.0\n",
      "Episode 130: Total Reward = 43.0\n",
      "Episode 131: Total Reward = 9.0\n",
      "Episode 132: Total Reward = 11.0\n",
      "Episode 133: Total Reward = 34.0\n",
      "Episode 134: Total Reward = 36.0\n",
      "Episode 135: Total Reward = 15.0\n",
      "Episode 136: Total Reward = 23.0\n",
      "Episode 137: Total Reward = 14.0\n",
      "Episode 138: Total Reward = 27.0\n",
      "Episode 139: Total Reward = 15.0\n",
      "Episode 140: Total Reward = 42.0\n",
      "Episode 141: Total Reward = 101.0\n",
      "Episode 142: Total Reward = 24.0\n",
      "Episode 143: Total Reward = 54.0\n",
      "Episode 144: Total Reward = 10.0\n",
      "Episode 145: Total Reward = 43.0\n",
      "Episode 146: Total Reward = 52.0\n",
      "Episode 147: Total Reward = 22.0\n",
      "Episode 148: Total Reward = 10.0\n",
      "Episode 149: Total Reward = 33.0\n",
      "Episode 150: Total Reward = 25.0\n",
      "Episode 151: Total Reward = 51.0\n",
      "Episode 152: Total Reward = 36.0\n",
      "Episode 153: Total Reward = 43.0\n",
      "Episode 154: Total Reward = 29.0\n",
      "Episode 155: Total Reward = 15.0\n",
      "Episode 156: Total Reward = 11.0\n",
      "Episode 157: Total Reward = 17.0\n",
      "Episode 158: Total Reward = 11.0\n",
      "Episode 159: Total Reward = 15.0\n",
      "Episode 160: Total Reward = 89.0\n",
      "Episode 161: Total Reward = 30.0\n",
      "Episode 162: Total Reward = 22.0\n",
      "Episode 163: Total Reward = 24.0\n",
      "Episode 164: Total Reward = 34.0\n",
      "Episode 165: Total Reward = 25.0\n",
      "Episode 166: Total Reward = 30.0\n",
      "Episode 167: Total Reward = 12.0\n",
      "Episode 168: Total Reward = 38.0\n",
      "Episode 169: Total Reward = 43.0\n",
      "Episode 170: Total Reward = 53.0\n",
      "Episode 171: Total Reward = 24.0\n",
      "Episode 172: Total Reward = 27.0\n",
      "Episode 173: Total Reward = 16.0\n",
      "Episode 174: Total Reward = 12.0\n",
      "Episode 175: Total Reward = 21.0\n",
      "Episode 176: Total Reward = 21.0\n",
      "Episode 177: Total Reward = 15.0\n",
      "Episode 178: Total Reward = 19.0\n",
      "Episode 179: Total Reward = 46.0\n",
      "Episode 180: Total Reward = 29.0\n",
      "Episode 181: Total Reward = 17.0\n",
      "Episode 182: Total Reward = 28.0\n",
      "Episode 183: Total Reward = 44.0\n",
      "Episode 184: Total Reward = 20.0\n",
      "Episode 185: Total Reward = 13.0\n",
      "Episode 186: Total Reward = 30.0\n",
      "Episode 187: Total Reward = 25.0\n",
      "Episode 188: Total Reward = 38.0\n",
      "Episode 189: Total Reward = 75.0\n",
      "Episode 190: Total Reward = 76.0\n",
      "Episode 191: Total Reward = 22.0\n",
      "Episode 192: Total Reward = 24.0\n",
      "Episode 193: Total Reward = 14.0\n",
      "Episode 194: Total Reward = 32.0\n",
      "Episode 195: Total Reward = 20.0\n",
      "Episode 196: Total Reward = 26.0\n",
      "Episode 197: Total Reward = 12.0\n",
      "Episode 198: Total Reward = 39.0\n",
      "Episode 199: Total Reward = 18.0\n",
      "Episode 200: Total Reward = 34.0\n",
      "Episode 201: Total Reward = 58.0\n",
      "Episode 202: Total Reward = 12.0\n",
      "Episode 203: Total Reward = 43.0\n",
      "Episode 204: Total Reward = 23.0\n",
      "Episode 205: Total Reward = 32.0\n",
      "Episode 206: Total Reward = 12.0\n",
      "Episode 207: Total Reward = 14.0\n",
      "Episode 208: Total Reward = 61.0\n",
      "Episode 209: Total Reward = 23.0\n",
      "Episode 210: Total Reward = 48.0\n",
      "Episode 211: Total Reward = 39.0\n",
      "Episode 212: Total Reward = 62.0\n",
      "Episode 213: Total Reward = 27.0\n",
      "Episode 214: Total Reward = 27.0\n",
      "Episode 215: Total Reward = 18.0\n",
      "Episode 216: Total Reward = 76.0\n",
      "Episode 217: Total Reward = 35.0\n",
      "Episode 218: Total Reward = 11.0\n",
      "Episode 219: Total Reward = 73.0\n",
      "Episode 220: Total Reward = 11.0\n",
      "Episode 221: Total Reward = 23.0\n",
      "Episode 222: Total Reward = 29.0\n",
      "Episode 223: Total Reward = 29.0\n",
      "Episode 224: Total Reward = 28.0\n",
      "Episode 225: Total Reward = 17.0\n",
      "Episode 226: Total Reward = 72.0\n",
      "Episode 227: Total Reward = 130.0\n",
      "Episode 228: Total Reward = 23.0\n",
      "Episode 229: Total Reward = 31.0\n",
      "Episode 230: Total Reward = 29.0\n",
      "Episode 231: Total Reward = 49.0\n",
      "Episode 232: Total Reward = 9.0\n",
      "Episode 233: Total Reward = 44.0\n",
      "Episode 234: Total Reward = 28.0\n",
      "Episode 235: Total Reward = 35.0\n",
      "Episode 236: Total Reward = 30.0\n",
      "Episode 237: Total Reward = 39.0\n",
      "Episode 238: Total Reward = 55.0\n",
      "Episode 239: Total Reward = 86.0\n",
      "Episode 240: Total Reward = 11.0\n",
      "Episode 241: Total Reward = 13.0\n",
      "Episode 242: Total Reward = 13.0\n",
      "Episode 243: Total Reward = 19.0\n",
      "Episode 244: Total Reward = 18.0\n",
      "Episode 245: Total Reward = 76.0\n",
      "Episode 246: Total Reward = 99.0\n",
      "Episode 247: Total Reward = 21.0\n",
      "Episode 248: Total Reward = 51.0\n",
      "Episode 249: Total Reward = 30.0\n",
      "Episode 250: Total Reward = 13.0\n",
      "Episode 251: Total Reward = 41.0\n",
      "Episode 252: Total Reward = 40.0\n",
      "Episode 253: Total Reward = 52.0\n",
      "Episode 254: Total Reward = 28.0\n",
      "Episode 255: Total Reward = 40.0\n",
      "Episode 256: Total Reward = 15.0\n",
      "Episode 257: Total Reward = 60.0\n",
      "Episode 258: Total Reward = 10.0\n",
      "Episode 259: Total Reward = 25.0\n",
      "Episode 260: Total Reward = 27.0\n",
      "Episode 261: Total Reward = 55.0\n",
      "Episode 262: Total Reward = 15.0\n",
      "Episode 263: Total Reward = 15.0\n",
      "Episode 264: Total Reward = 38.0\n",
      "Episode 265: Total Reward = 48.0\n",
      "Episode 266: Total Reward = 21.0\n",
      "Episode 267: Total Reward = 86.0\n",
      "Episode 268: Total Reward = 57.0\n",
      "Episode 269: Total Reward = 55.0\n",
      "Episode 270: Total Reward = 26.0\n",
      "Episode 271: Total Reward = 13.0\n",
      "Episode 272: Total Reward = 34.0\n",
      "Episode 273: Total Reward = 31.0\n",
      "Episode 274: Total Reward = 40.0\n",
      "Episode 275: Total Reward = 28.0\n",
      "Episode 276: Total Reward = 20.0\n",
      "Episode 277: Total Reward = 39.0\n",
      "Episode 278: Total Reward = 65.0\n",
      "Episode 279: Total Reward = 45.0\n",
      "Episode 280: Total Reward = 46.0\n",
      "Episode 281: Total Reward = 23.0\n",
      "Episode 282: Total Reward = 69.0\n",
      "Episode 283: Total Reward = 44.0\n",
      "Episode 284: Total Reward = 46.0\n",
      "Episode 285: Total Reward = 18.0\n",
      "Episode 286: Total Reward = 53.0\n",
      "Episode 287: Total Reward = 46.0\n",
      "Episode 288: Total Reward = 56.0\n",
      "Episode 289: Total Reward = 26.0\n",
      "Episode 290: Total Reward = 28.0\n",
      "Episode 291: Total Reward = 48.0\n",
      "Episode 292: Total Reward = 12.0\n",
      "Episode 293: Total Reward = 10.0\n",
      "Episode 294: Total Reward = 61.0\n",
      "Episode 295: Total Reward = 75.0\n",
      "Episode 296: Total Reward = 50.0\n",
      "Episode 297: Total Reward = 58.0\n",
      "Episode 298: Total Reward = 15.0\n",
      "Episode 299: Total Reward = 23.0\n",
      "Episode 300: Total Reward = 100.0\n",
      "Episode 301: Total Reward = 34.0\n",
      "Episode 302: Total Reward = 19.0\n",
      "Episode 303: Total Reward = 40.0\n",
      "Episode 304: Total Reward = 29.0\n",
      "Episode 305: Total Reward = 44.0\n",
      "Episode 306: Total Reward = 63.0\n",
      "Episode 307: Total Reward = 27.0\n",
      "Episode 308: Total Reward = 30.0\n",
      "Episode 309: Total Reward = 96.0\n",
      "Episode 310: Total Reward = 24.0\n",
      "Episode 311: Total Reward = 64.0\n",
      "Episode 312: Total Reward = 22.0\n",
      "Episode 313: Total Reward = 51.0\n",
      "Episode 314: Total Reward = 12.0\n",
      "Episode 315: Total Reward = 66.0\n",
      "Episode 316: Total Reward = 19.0\n",
      "Episode 317: Total Reward = 61.0\n",
      "Episode 318: Total Reward = 21.0\n",
      "Episode 319: Total Reward = 56.0\n",
      "Episode 320: Total Reward = 14.0\n",
      "Episode 321: Total Reward = 32.0\n",
      "Episode 322: Total Reward = 134.0\n",
      "Episode 323: Total Reward = 14.0\n",
      "Episode 324: Total Reward = 59.0\n",
      "Episode 325: Total Reward = 87.0\n",
      "Episode 326: Total Reward = 64.0\n",
      "Episode 327: Total Reward = 29.0\n",
      "Episode 328: Total Reward = 86.0\n",
      "Episode 329: Total Reward = 40.0\n",
      "Episode 330: Total Reward = 98.0\n",
      "Episode 331: Total Reward = 45.0\n",
      "Episode 332: Total Reward = 77.0\n",
      "Episode 333: Total Reward = 123.0\n",
      "Episode 334: Total Reward = 94.0\n",
      "Episode 335: Total Reward = 61.0\n",
      "Episode 336: Total Reward = 19.0\n",
      "Episode 337: Total Reward = 103.0\n",
      "Episode 338: Total Reward = 48.0\n",
      "Episode 339: Total Reward = 52.0\n",
      "Episode 340: Total Reward = 20.0\n",
      "Episode 341: Total Reward = 39.0\n",
      "Episode 342: Total Reward = 70.0\n",
      "Episode 343: Total Reward = 19.0\n",
      "Episode 344: Total Reward = 12.0\n",
      "Episode 345: Total Reward = 15.0\n",
      "Episode 346: Total Reward = 111.0\n",
      "Episode 347: Total Reward = 38.0\n",
      "Episode 348: Total Reward = 16.0\n",
      "Episode 349: Total Reward = 52.0\n",
      "Episode 350: Total Reward = 48.0\n",
      "Episode 351: Total Reward = 36.0\n",
      "Episode 352: Total Reward = 24.0\n",
      "Episode 353: Total Reward = 15.0\n",
      "Episode 354: Total Reward = 63.0\n",
      "Episode 355: Total Reward = 50.0\n",
      "Episode 356: Total Reward = 141.0\n",
      "Episode 357: Total Reward = 67.0\n",
      "Episode 358: Total Reward = 25.0\n",
      "Episode 359: Total Reward = 18.0\n",
      "Episode 360: Total Reward = 24.0\n",
      "Episode 361: Total Reward = 33.0\n",
      "Episode 362: Total Reward = 34.0\n",
      "Episode 363: Total Reward = 34.0\n",
      "Episode 364: Total Reward = 64.0\n",
      "Episode 365: Total Reward = 72.0\n",
      "Episode 366: Total Reward = 79.0\n",
      "Episode 367: Total Reward = 33.0\n",
      "Episode 368: Total Reward = 69.0\n",
      "Episode 369: Total Reward = 175.0\n",
      "Episode 370: Total Reward = 25.0\n",
      "Episode 371: Total Reward = 56.0\n",
      "Episode 372: Total Reward = 13.0\n",
      "Episode 373: Total Reward = 30.0\n",
      "Episode 374: Total Reward = 27.0\n",
      "Episode 375: Total Reward = 109.0\n",
      "Episode 376: Total Reward = 59.0\n",
      "Episode 377: Total Reward = 83.0\n",
      "Episode 378: Total Reward = 37.0\n",
      "Episode 379: Total Reward = 18.0\n",
      "Episode 380: Total Reward = 14.0\n",
      "Episode 381: Total Reward = 21.0\n",
      "Episode 382: Total Reward = 47.0\n",
      "Episode 383: Total Reward = 44.0\n",
      "Episode 384: Total Reward = 62.0\n",
      "Episode 385: Total Reward = 84.0\n",
      "Episode 386: Total Reward = 120.0\n",
      "Episode 387: Total Reward = 162.0\n",
      "Episode 388: Total Reward = 47.0\n",
      "Episode 389: Total Reward = 12.0\n",
      "Episode 390: Total Reward = 124.0\n",
      "Episode 391: Total Reward = 47.0\n",
      "Episode 392: Total Reward = 51.0\n",
      "Episode 393: Total Reward = 68.0\n",
      "Episode 394: Total Reward = 51.0\n",
      "Episode 395: Total Reward = 24.0\n",
      "Episode 396: Total Reward = 28.0\n",
      "Episode 397: Total Reward = 26.0\n",
      "Episode 398: Total Reward = 44.0\n",
      "Episode 399: Total Reward = 69.0\n",
      "Episode 400: Total Reward = 36.0\n",
      "Episode 401: Total Reward = 70.0\n",
      "Episode 402: Total Reward = 34.0\n",
      "Episode 403: Total Reward = 163.0\n",
      "Episode 404: Total Reward = 25.0\n",
      "Episode 405: Total Reward = 21.0\n",
      "Episode 406: Total Reward = 18.0\n",
      "Episode 407: Total Reward = 46.0\n",
      "Episode 408: Total Reward = 13.0\n",
      "Episode 409: Total Reward = 118.0\n",
      "Episode 410: Total Reward = 15.0\n",
      "Episode 411: Total Reward = 13.0\n",
      "Episode 412: Total Reward = 77.0\n",
      "Episode 413: Total Reward = 88.0\n",
      "Episode 414: Total Reward = 55.0\n",
      "Episode 415: Total Reward = 124.0\n",
      "Episode 416: Total Reward = 97.0\n",
      "Episode 417: Total Reward = 124.0\n",
      "Episode 418: Total Reward = 54.0\n",
      "Episode 419: Total Reward = 34.0\n",
      "Episode 420: Total Reward = 32.0\n",
      "Episode 421: Total Reward = 16.0\n",
      "Episode 422: Total Reward = 26.0\n",
      "Episode 423: Total Reward = 99.0\n",
      "Episode 424: Total Reward = 132.0\n",
      "Episode 425: Total Reward = 11.0\n",
      "Episode 426: Total Reward = 39.0\n",
      "Episode 427: Total Reward = 91.0\n",
      "Episode 428: Total Reward = 73.0\n",
      "Episode 429: Total Reward = 112.0\n",
      "Episode 430: Total Reward = 81.0\n",
      "Episode 431: Total Reward = 80.0\n",
      "Episode 432: Total Reward = 57.0\n",
      "Episode 433: Total Reward = 42.0\n",
      "Episode 434: Total Reward = 23.0\n",
      "Episode 435: Total Reward = 100.0\n",
      "Episode 436: Total Reward = 24.0\n",
      "Episode 437: Total Reward = 67.0\n",
      "Episode 438: Total Reward = 169.0\n",
      "Episode 439: Total Reward = 42.0\n",
      "Episode 440: Total Reward = 25.0\n",
      "Episode 441: Total Reward = 169.0\n",
      "Episode 442: Total Reward = 52.0\n",
      "Episode 443: Total Reward = 46.0\n",
      "Episode 444: Total Reward = 149.0\n",
      "Episode 445: Total Reward = 24.0\n",
      "Episode 446: Total Reward = 103.0\n",
      "Episode 447: Total Reward = 78.0\n",
      "Episode 448: Total Reward = 20.0\n",
      "Episode 449: Total Reward = 88.0\n",
      "Episode 450: Total Reward = 11.0\n",
      "Episode 451: Total Reward = 17.0\n",
      "Episode 452: Total Reward = 107.0\n",
      "Episode 453: Total Reward = 22.0\n",
      "Episode 454: Total Reward = 123.0\n",
      "Episode 455: Total Reward = 41.0\n",
      "Episode 456: Total Reward = 44.0\n",
      "Episode 457: Total Reward = 50.0\n",
      "Episode 458: Total Reward = 80.0\n",
      "Episode 459: Total Reward = 21.0\n",
      "Episode 460: Total Reward = 81.0\n",
      "Episode 461: Total Reward = 89.0\n",
      "Episode 462: Total Reward = 54.0\n",
      "Episode 463: Total Reward = 72.0\n",
      "Episode 464: Total Reward = 13.0\n",
      "Episode 465: Total Reward = 64.0\n",
      "Episode 466: Total Reward = 40.0\n",
      "Episode 467: Total Reward = 32.0\n",
      "Episode 468: Total Reward = 13.0\n",
      "Episode 469: Total Reward = 30.0\n",
      "Episode 470: Total Reward = 159.0\n",
      "Episode 471: Total Reward = 20.0\n",
      "Episode 472: Total Reward = 60.0\n",
      "Episode 473: Total Reward = 181.0\n",
      "Episode 474: Total Reward = 41.0\n",
      "Episode 475: Total Reward = 60.0\n",
      "Episode 476: Total Reward = 15.0\n",
      "Episode 477: Total Reward = 64.0\n",
      "Episode 478: Total Reward = 145.0\n",
      "Episode 479: Total Reward = 56.0\n",
      "Episode 480: Total Reward = 52.0\n",
      "Episode 481: Total Reward = 85.0\n",
      "Episode 482: Total Reward = 131.0\n",
      "Episode 483: Total Reward = 26.0\n",
      "Episode 484: Total Reward = 35.0\n",
      "Episode 485: Total Reward = 32.0\n",
      "Episode 486: Total Reward = 16.0\n",
      "Episode 487: Total Reward = 22.0\n",
      "Episode 488: Total Reward = 92.0\n",
      "Episode 489: Total Reward = 65.0\n",
      "Episode 490: Total Reward = 31.0\n",
      "Episode 491: Total Reward = 49.0\n",
      "Episode 492: Total Reward = 114.0\n",
      "Episode 493: Total Reward = 79.0\n",
      "Episode 494: Total Reward = 45.0\n",
      "Episode 495: Total Reward = 106.0\n",
      "Episode 496: Total Reward = 44.0\n",
      "Episode 497: Total Reward = 50.0\n",
      "Episode 498: Total Reward = 123.0\n",
      "Episode 499: Total Reward = 28.0\n",
      "Episode 500: Total Reward = 34.0\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        action = choose_action(state, epsilon)  # Choose action\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        \n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Store the experience\n",
    "        replay_memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "        # Train the model\n",
    "        train_model()\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Update epsilon\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    # Sync weights with the target model periodically\n",
    "    if episode % 20 == 0:\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "    if total_reward >= 400:\n",
    "        model.save(f\"../model/dqn-model-{episode}.keras\")\n",
    "    \n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../model/dqn-model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "\n",
    "def test():\n",
    "    test_env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "    for e in range(10):\n",
    "        state, _ = test_env.reset()\n",
    "        done = False\n",
    "        i = 0\n",
    "\n",
    "        while not done:\n",
    "            test_env.render()\n",
    "            action = np.argmax(model.predict(state[np.newaxis], verbose=0))\n",
    "            next_state, reward, terminated, truncated, _ = test_env.step(action)\n",
    "\n",
    "            done = terminated or truncated\n",
    "\n",
    "            state = next_state\n",
    "            i += 1\n",
    "            if done:\n",
    "                print(\"episode: {}/{}, score: {}\".format(e, 10, i))\n",
    "                break\n",
    "    test_env.close()\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 17:34:51.078 Python[29485:9695063] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/hc/_rm2mjw14y9_r7933xkcw3p80000gn/T/org.python.python.savedState\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/10, score: 210\n",
      "episode: 1/10, score: 316\n",
      "episode: 2/10, score: 215\n",
      "episode: 3/10, score: 305\n",
      "episode: 4/10, score: 243\n",
      "episode: 5/10, score: 290\n",
      "episode: 6/10, score: 218\n",
      "episode: 7/10, score: 221\n",
      "episode: 8/10, score: 257\n",
      "episode: 9/10, score: 217\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
